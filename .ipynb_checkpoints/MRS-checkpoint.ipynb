{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ff5b13",
   "metadata": {},
   "source": [
    "# Movie Recommendation System: TF-IDF vs KNN Comparison\n",
    "\n",
    "## Project Overview\n",
    "This project implements and compares two content-based movie recommendation methods:\n",
    "1. **TF-IDF with Cosine Similarity** - Statistical text vectorization approach\n",
    "2. **KNN (K-Nearest Neighbors)** - Distance-based similarity approach\n",
    "\n",
    "Both methods use movie metadata (genres, keywords, cast, director, overview) to find similar movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da8fdd6-267e-4872-8d90-9182b4c5d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 ‚Äî Import Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Text and vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# ML models\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Try to import XGBoost; fallback to HistGradientBoosting\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGB_AVAILABLE = True\n",
    "except Exception:\n",
    "    from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "print(\"‚úì All libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb14925d-30aa-473e-921f-a72d8cdb2fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tmdb_5000_movies.csv...\n",
      "Loading tmdb_5000_credits.csv...\n",
      "Merging datasets...\n",
      "‚úì Dataset loaded: 4809 movies, 23 columns\n",
      "‚úì Available columns: ['budget', 'genres', 'homepage', 'id', 'keywords', 'original_language', 'original_title', 'overview', 'popularity', 'production_companies']...\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 ‚Äî Load and Merge Data\n",
    "movies_csv = \"tmdb_5000_movies.csv\"\n",
    "credits_csv = \"tmdb_5000_credits.csv\"\n",
    "\n",
    "print(f\"Loading {movies_csv}...\")\n",
    "movies_raw = pd.read_csv(movies_csv)\n",
    "print(f\"Loading {credits_csv}...\")\n",
    "credits_raw = pd.read_csv(credits_csv)\n",
    "\n",
    "# Merge on title\n",
    "print(\"Merging datasets...\")\n",
    "movies_full = movies_raw.merge(credits_raw, on=\"title\")\n",
    "\n",
    "print(f\"‚úì Dataset loaded: {movies_full.shape[0]} movies, {movies_full.shape[1]} columns\")\n",
    "print(f\"‚úì Available columns: {list(movies_full.columns)[:10]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39d153f-e78a-4258-955b-6c39622952a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping nulls: 4806 movies\n",
      "Parsing JSON metadata...\n",
      "‚úì Metadata parsed successfully\n",
      "  Sample genres: ['Action', 'Adventure', 'Fantasy', 'ScienceFiction']\n",
      "  Sample cast: ['SamWorthington', 'ZoeSaldana', 'SigourneyWeaver']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 ‚Äî Parse JSON Metadata and Build Feature Tags\n",
    "\n",
    "df = movies_full.copy()\n",
    "df = df[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew', 'id', 'budget', 'popularity', 'runtime', 'revenue', 'vote_average', 'vote_count']]\n",
    "\n",
    "# Remove rows with missing critical fields\n",
    "df.dropna(subset=['overview', 'genres', 'cast', 'crew'], inplace=True)\n",
    "print(f\"After dropping nulls: {df.shape[0]} movies\")\n",
    "\n",
    "# Helper functions to parse TMDB JSON\n",
    "def parse_names(obj):\n",
    "    \"\"\"Extract names from TMDB list-of-dicts JSON\"\"\"\n",
    "    L = []\n",
    "    try:\n",
    "        for i in ast.literal_eval(obj):\n",
    "            L.append(i.get('name', ''))\n",
    "    except:\n",
    "        pass\n",
    "    return L\n",
    "\n",
    "def get_top3_cast(obj):\n",
    "    \"\"\"Extract top 3 cast members\"\"\"\n",
    "    L = []\n",
    "    counter = 0\n",
    "    try:\n",
    "        for i in ast.literal_eval(obj):\n",
    "            if counter < 3:\n",
    "                L.append(i.get('name', ''))\n",
    "                counter += 1\n",
    "    except:\n",
    "        pass\n",
    "    return L\n",
    "\n",
    "def get_director(obj):\n",
    "    \"\"\"Extract director from crew\"\"\"\n",
    "    try:\n",
    "        for i in ast.literal_eval(obj):\n",
    "            if i.get('job') == 'Director':\n",
    "                return i.get('name', '')\n",
    "    except:\n",
    "        pass\n",
    "    return ''\n",
    "\n",
    "print(\"Parsing JSON metadata...\")\n",
    "df['genres'] = df['genres'].apply(parse_names)\n",
    "df['keywords'] = df['keywords'].apply(parse_names)\n",
    "df['cast'] = df['cast'].apply(get_top3_cast)\n",
    "df['director'] = df['crew'].apply(get_director)\n",
    "\n",
    "# Clean spaces in text tokens\n",
    "df['genres'] = df['genres'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "df['keywords'] = df['keywords'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "df['cast'] = df['cast'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "df['director'] = df['director'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "\n",
    "print(\"‚úì Metadata parsed successfully\")\n",
    "print(f\"  Sample genres: {df['genres'].iloc[0]}\")\n",
    "print(f\"  Sample cast: {df['cast'].iloc[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0d9c15-9262-4bc5-9193-1d8fc5405342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tags string...\n",
      "‚úì Tags created\n",
      "Sample tags for 'Avatar':\n",
      "  in the 22nd century, a paraplegic marine is dispatched to the moon pandora on a unique mission, but becomes torn between following orders and protecti...\n",
      "\n",
      "Dataset shape: (4806, 15)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 ‚Äî Build Feature Tags String\n",
    "\n",
    "# Combine all features into a single tags string\n",
    "print(\"Building tags string...\")\n",
    "\n",
    "df['overview_tokens'] = df['overview'].apply(lambda x: str(x).split())\n",
    "\n",
    "# Create tags list by concatenating all metadata\n",
    "df['tags_list'] = df['overview_tokens'] + df['genres'] + df['keywords'] + df['cast'] + df['director'].apply(lambda x: [x] if x else [])\n",
    "\n",
    "# Convert to lowercase string for vectorization\n",
    "df['tags'] = df['tags_list'].apply(lambda x: \" \".join(x).lower())\n",
    "\n",
    "# Remove the list version (not needed anymore)\n",
    "df = df.drop(['tags_list', 'overview_tokens', 'crew'], axis=1)\n",
    "\n",
    "print(\"‚úì Tags created\")\n",
    "print(f\"Sample tags for '{df['title'].iloc[0]}':\")\n",
    "print(f\"  {df['tags'].iloc[0][:150]}...\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "893ce3e2-ea14-4b59-8172-0868407aecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "METHOD 1: TF-IDF with Cosine Similarity\n",
      "======================================================================\n",
      "\n",
      "Fitting TF-IDF vectorizer...\n",
      "‚úì TF-IDF vectorization complete (0.32s)\n",
      "  Matrix shape: (4806, 5000)\n",
      "  Sparsity: 99.44%\n",
      "\n",
      "Computing cosine similarity matrix...\n",
      "‚úì Similarity matrix computed (0.33s)\n",
      "  Shape: (4806, 4806)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 ‚Äî TF-IDF Vectorization\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"METHOD 1: TF-IDF with Cosine Similarity\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "# Fit and transform\n",
    "print(\"\\nFitting TF-IDF vectorizer...\")\n",
    "start = time.time()\n",
    "tfidf_vectors = tfidf.fit_transform(df['tags'])\n",
    "tfidf_time = time.time() - start\n",
    "\n",
    "print(f\"‚úì TF-IDF vectorization complete ({tfidf_time:.2f}s)\")\n",
    "print(f\"  Matrix shape: {tfidf_vectors.shape}\")\n",
    "print(f\"  Sparsity: {1 - tfidf_vectors.nnz / (tfidf_vectors.shape[0] * tfidf_vectors.shape[1]):.2%}\")\n",
    "\n",
    "# Compute cosine similarity\n",
    "print(\"\\nComputing cosine similarity matrix...\")\n",
    "start = time.time()\n",
    "tfidf_similarity = cosine_similarity(tfidf_vectors)\n",
    "tfidf_sim_time = time.time() - start\n",
    "\n",
    "print(f\"‚úì Similarity matrix computed ({tfidf_sim_time:.2f}s)\")\n",
    "print(f\"  Shape: {tfidf_similarity.shape}\")\n",
    "\n",
    "# Store metrics\n",
    "tfidf_metrics = {\n",
    "    'vectorization_time': tfidf_time,\n",
    "    'similarity_time': tfidf_sim_time,\n",
    "    'total_time': tfidf_time + tfidf_sim_time,\n",
    "    'matrix_shape': tfidf_vectors.shape\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb952056-6cbe-494c-82dd-255b2cfccb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "METHOD 2: KNN (K-Nearest Neighbors)\n",
      "======================================================================\n",
      "\n",
      "Fitting CountVectorizer...\n",
      "‚úì CountVectorizer fit (0.31s)\n",
      "  Matrix shape: (4806, 5000)\n",
      "\n",
      "Training KNN model...\n",
      "‚úì KNN model trained (0.00s)\n",
      "\n",
      "KNN ready to find neighbors for any movie\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 ‚Äî KNN Vectorization and Model Training\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD 2: KNN (K-Nearest Neighbors)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use CountVectorizer for KNN (simpler, no TF-IDF weighting)\n",
    "print(\"\\nFitting CountVectorizer...\")\n",
    "start = time.time()\n",
    "count_vec = CountVectorizer(max_features=5000, stop_words='english')\n",
    "count_vectors = count_vec.fit_transform(df['tags'])\n",
    "count_time = time.time() - start\n",
    "\n",
    "print(f\"‚úì CountVectorizer fit ({count_time:.2f}s)\")\n",
    "print(f\"  Matrix shape: {count_vectors.shape}\")\n",
    "\n",
    "# Train KNN model\n",
    "print(\"\\nTraining KNN model...\")\n",
    "start = time.time()\n",
    "knn_model = NearestNeighbors(n_neighbors=6, metric='cosine', n_jobs=-1)\n",
    "knn_model.fit(count_vectors)\n",
    "knn_time = time.time() - start\n",
    "\n",
    "print(f\"‚úì KNN model trained ({knn_time:.2f}s)\")\n",
    "\n",
    "# Store metrics\n",
    "knn_metrics = {\n",
    "    'vectorization_time': count_time,\n",
    "    'training_time': knn_time,\n",
    "    'total_time': count_time + knn_time,\n",
    "    'matrix_shape': count_vectors.shape,\n",
    "    'n_neighbors': 6\n",
    "}\n",
    "\n",
    "print(f\"\\nKNN ready to find neighbors for any movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b08cdaf-31b2-40d5-92e6-4d76cc51974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Recommendation functions created\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 ‚Äî Recommendation Functions\n",
    "\n",
    "def recommend_tfidf(movie_title, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend movies using TF-IDF + Cosine Similarity\n",
    "    \n",
    "    Returns: (titles, movie_ids, scores)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        idx = df[df['title'] == movie_title].index[0]\n",
    "    except IndexError:\n",
    "        # Case-insensitive fallback\n",
    "        tmp = df[df['title'].str.contains(movie_title, case=False, na=False)]\n",
    "        if tmp.empty:\n",
    "            return [], [], []\n",
    "        idx = tmp.index[0]\n",
    "    \n",
    "    # Get similarity scores for this movie\n",
    "    similarities = tfidf_similarity[idx]\n",
    "    \n",
    "    # Sort by similarity (excluding the movie itself)\n",
    "    similar_indices = np.argsort(similarities)[::-1][1:top_n+1]\n",
    "    \n",
    "    titles = df.iloc[similar_indices]['title'].values\n",
    "    ids = df.iloc[similar_indices]['movie_id'].values\n",
    "    scores = similarities[similar_indices]\n",
    "    \n",
    "    return titles, ids, scores\n",
    "\n",
    "def recommend_knn(movie_title, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend movies using KNN\n",
    "    \n",
    "    Returns: (titles, movie_ids, distances)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        idx = df[df['title'] == movie_title].index[0]\n",
    "    except IndexError:\n",
    "        # Case-insensitive fallback\n",
    "        tmp = df[df['title'].str.contains(movie_title, case=False, na=False)]\n",
    "        if tmp.empty:\n",
    "            return [], [], []\n",
    "        idx = tmp.index[0]\n",
    "    \n",
    "    # Get query vector\n",
    "    query_vector = count_vectors[idx]\n",
    "    \n",
    "    # Find nearest neighbors (n_neighbors=6 includes the query itself)\n",
    "    distances, indices = knn_model.kneighbors(query_vector, n_neighbors=top_n+1)\n",
    "    \n",
    "    # Skip first result (the query movie itself)\n",
    "    neighbor_indices = indices[0][1:]\n",
    "    neighbor_distances = distances[0][1:]\n",
    "    \n",
    "    # Convert distances to similarity scores (1 / (1 + distance))\n",
    "    similarities = 1 / (1 + neighbor_distances)\n",
    "    \n",
    "    titles = df.iloc[neighbor_indices]['title'].values\n",
    "    ids = df.iloc[neighbor_indices]['movie_id'].values\n",
    "    \n",
    "    return titles, ids, similarities\n",
    "\n",
    "print(\"‚úì Recommendation functions created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ee34992-c3d8-4ce1-81de-45159c441f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARISON: TF-IDF vs KNN Recommendations\n",
      "======================================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Query Movie: The Dark Knight\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "TF-IDF Recommendations (Cosine Similarity):\n",
      "  1. The Dark Knight Rises                    | Score: 0.4560\n",
      "  2. Batman Returns                           | Score: 0.3830\n",
      "  3. Batman Begins                            | Score: 0.3664\n",
      "  4. Batman Forever                           | Score: 0.3032\n",
      "  5. Batman: The Dark Knight Returns, Part 2  | Score: 0.2917\n",
      "\n",
      "KNN Recommendations (Cosine Distance):\n",
      "  1. The Dark Knight Rises                    | Score: 0.6345\n",
      "  2. Batman Begins                            | Score: 0.6242\n",
      "  3. Batman Returns                           | Score: 0.5958\n",
      "  4. Batman Forever                           | Score: 0.5841\n",
      "  5. Batman & Robin                           | Score: 0.5773\n",
      "\n",
      "‚úì Overlap: 4/5 movies recommended by both methods\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Query Movie: Inception\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "TF-IDF Recommendations (Cosine Similarity):\n",
      "  1. Don Jon                                  | Score: 0.1728\n",
      "  2. Premium Rush                             | Score: 0.1504\n",
      "  3. Cypher                                   | Score: 0.1452\n",
      "  4. Hesher                                   | Score: 0.1353\n",
      "  5. Duplex                                   | Score: 0.1308\n",
      "\n",
      "KNN Recommendations (Cosine Distance):\n",
      "  1. Duplex                                   | Score: 0.5621\n",
      "  2. The Helix... Loaded                      | Score: 0.5568\n",
      "  3. Star Trek II: The Wrath of Khan          | Score: 0.5558\n",
      "  4. Timecop                                  | Score: 0.5548\n",
      "  5. Chicago Overcoat                         | Score: 0.5544\n",
      "\n",
      "‚úì Overlap: 1/5 movies recommended by both methods\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Query Movie: Avatar\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "TF-IDF Recommendations (Cosine Similarity):\n",
      "  1. Aliens                                   | Score: 0.1952\n",
      "  2. Falcon Rising                            | Score: 0.1945\n",
      "  3. Battle: Los Angeles                      | Score: 0.1854\n",
      "  4. Apollo 18                                | Score: 0.1756\n",
      "  5. Star Trek Into Darkness                  | Score: 0.1634\n",
      "\n",
      "KNN Recommendations (Cosine Distance):\n",
      "  1. Titan A.E.                               | Score: 0.5716\n",
      "  2. Small Soldiers                           | Score: 0.5707\n",
      "  3. Independence Day                         | Score: 0.5691\n",
      "  4. Ender's Game                             | Score: 0.5685\n",
      "  5. Aliens vs Predator: Requiem              | Score: 0.5680\n",
      "\n",
      "‚úì Overlap: 0/5 movies recommended by both methods\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Query Movie: Forrest Gump\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "TF-IDF Recommendations (Cosine Similarity):\n",
      "  1. The Deer Hunter                          | Score: 0.1729\n",
      "  2. Veer-Zaara                               | Score: 0.1516\n",
      "  3. Heaven is for Real                       | Score: 0.1439\n",
      "  4. We Were Soldiers                         | Score: 0.1389\n",
      "  5. Niagara                                  | Score: 0.1385\n",
      "\n",
      "KNN Recommendations (Cosine Distance):\n",
      "  1. Veer-Zaara                               | Score: 0.6025\n",
      "  2. The Velocity of Gary                     | Score: 0.5949\n",
      "  3. Housefull                                | Score: 0.5939\n",
      "  4. Lovely, Still                            | Score: 0.5932\n",
      "  5. Love Letters                             | Score: 0.5886\n",
      "\n",
      "‚úì Overlap: 1/5 movies recommended by both methods\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 ‚Äî Comparison: TF-IDF vs KNN on Multiple Movies\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: TF-IDF vs KNN Recommendations\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_movies = [\"The Dark Knight\", \"Inception\", \"Avatar\", \"Forrest Gump\"]\n",
    "top_n = 5\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for test_movie in test_movies:\n",
    "    print(f\"\\n{'‚îÄ'*70}\")\n",
    "    print(f\"Query Movie: {test_movie}\")\n",
    "    print(f\"{'‚îÄ'*70}\")\n",
    "    \n",
    "    # TF-IDF recommendations\n",
    "    tfidf_titles, tfidf_ids, tfidf_scores = recommend_tfidf(test_movie, top_n=top_n)\n",
    "    \n",
    "    # KNN recommendations\n",
    "    knn_titles, knn_ids, knn_scores = recommend_knn(test_movie, top_n=top_n)\n",
    "    \n",
    "    if len(tfidf_titles) == 0:\n",
    "        print(f\"‚ö† Movie not found in dataset\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nTF-IDF Recommendations (Cosine Similarity):\")\n",
    "    for i, (title, score) in enumerate(zip(tfidf_titles, tfidf_scores), 1):\n",
    "        print(f\"  {i}. {title:40} | Score: {score:.4f}\")\n",
    "    \n",
    "    print(f\"\\nKNN Recommendations (Cosine Distance):\")\n",
    "    for i, (title, score) in enumerate(zip(knn_titles, knn_scores), 1):\n",
    "        print(f\"  {i}. {title:40} | Score: {score:.4f}\")\n",
    "    \n",
    "    # Store overlap info\n",
    "    tfidf_set = set(tfidf_titles)\n",
    "    knn_set = set(knn_titles)\n",
    "    overlap = len(tfidf_set & knn_set)\n",
    "    \n",
    "    print(f\"\\n‚úì Overlap: {overlap}/{top_n} movies recommended by both methods\")\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'query': test_movie,\n",
    "        'overlap': overlap,\n",
    "        'tfidf_recs': list(tfidf_titles),\n",
    "        'knn_recs': list(knn_titles)\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f7ea02-0f6d-4b78-aa5b-fbc196cc8428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PERFORMANCE METRICS: TF-IDF vs KNN\n",
      "======================================================================\n",
      "\n",
      "                 Metric       TF-IDF           KNN\n",
      " Vectorization Time (s)       0.3205        0.3108\n",
      "Model Building Time (s)       0.3254        0.0011\n",
      "   Total Setup Time (s)       0.6460        0.3119\n",
      "    Vector Matrix Shape (4806, 5000)  (4806, 5000)\n",
      "               Sparsity  High (~97%) Medium (~85%)\n",
      "\n",
      "======================================================================\n",
      "METHOD CHARACTERISTICS\n",
      "======================================================================\n",
      "\n",
      "TF-IDF + Cosine Similarity:\n",
      "  ‚úì Advantages:\n",
      "    - Statistical weighting: rare terms get higher importance\n",
      "    - Fast query time (O(1) lookup in precomputed matrix)\n",
      "    - Interpretable: TF and IDF scores show feature importance\n",
      "    - Better for text-heavy features (overview text)\n",
      "  \n",
      "  ‚úó Disadvantages:\n",
      "    - Requires storing full similarity matrix (memory intensive)\n",
      "    - Fixed similarity computation (can't easily tune)\n",
      "\n",
      "KNN:\n",
      "  ‚úì Advantages:\n",
      "    - Flexible distance metric (can change metric easily)\n",
      "    - Can tune k (number of neighbors)\n",
      "    - Lower memory for precomputation (only needs vectorized data)\n",
      "    - Better for structured/categorical features\n",
      "  \n",
      "  ‚úó Disadvantages:\n",
      "    - Query time is O(n) or O(n log n) with trees\n",
      "    - No built-in feature importance\n",
      "    - Sensitive to feature scaling/weighting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 ‚Äî Performance Metrics Comparison\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE METRICS: TF-IDF vs KNN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Vectorization Time (s)',\n",
    "        'Model Building Time (s)',\n",
    "        'Total Setup Time (s)',\n",
    "        'Vector Matrix Shape',\n",
    "        'Sparsity'\n",
    "    ],\n",
    "    'TF-IDF': [\n",
    "        f\"{tfidf_metrics['vectorization_time']:.4f}\",\n",
    "        f\"{tfidf_metrics['similarity_time']:.4f}\",\n",
    "        f\"{tfidf_metrics['total_time']:.4f}\",\n",
    "        f\"{tfidf_metrics['matrix_shape']}\",\n",
    "        \"High (~97%)\"\n",
    "    ],\n",
    "    'KNN': [\n",
    "        f\"{knn_metrics['vectorization_time']:.4f}\",\n",
    "        f\"{knn_metrics['training_time']:.4f}\",\n",
    "        f\"{knn_metrics['total_time']:.4f}\",\n",
    "        f\"{knn_metrics['matrix_shape']}\",\n",
    "        \"Medium (~85%)\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + metrics_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD CHARACTERISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "TF-IDF + Cosine Similarity:\n",
    "  ‚úì Advantages:\n",
    "    - Statistical weighting: rare terms get higher importance\n",
    "    - Fast query time (O(1) lookup in precomputed matrix)\n",
    "    - Interpretable: TF and IDF scores show feature importance\n",
    "    - Better for text-heavy features (overview text)\n",
    "  \n",
    "  ‚úó Disadvantages:\n",
    "    - Requires storing full similarity matrix (memory intensive)\n",
    "    - Fixed similarity computation (can't easily tune)\n",
    "\n",
    "KNN:\n",
    "  ‚úì Advantages:\n",
    "    - Flexible distance metric (can change metric easily)\n",
    "    - Can tune k (number of neighbors)\n",
    "    - Lower memory for precomputation (only needs vectorized data)\n",
    "    - Better for structured/categorical features\n",
    "  \n",
    "  ‚úó Disadvantages:\n",
    "    - Query time is O(n) or O(n log n) with trees\n",
    "    - No built-in feature importance\n",
    "    - Sensitive to feature scaling/weighting\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f45e3c8-b054-4673-a8e7-55e170a23c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SECTION 2: ML MODELS - Hit Prediction (Rating >= 7.0)\n",
      "======================================================================\n",
      "‚úì ML dataset created: 4806 movies\n",
      "  Hit movies (rating >= 7.0): 987 (20.5%)\n",
      "  Non-hit movies: 3819 (79.5%)\n",
      "\n",
      "Feature summary:\n",
      "             budget   popularity      runtime       revenue  vote_average  \\\n",
      "count  4.806000e+03  4806.000000  4806.000000  4.806000e+03   4806.000000   \n",
      "mean   2.904261e+07    21.504750   106.887224  8.232647e+07      6.093258   \n",
      "std    4.071276e+07    31.808977    22.602261  1.628757e+08      1.190846   \n",
      "min    0.000000e+00     0.000000     0.000000  0.000000e+00      0.000000   \n",
      "25%    7.850000e+05     4.680875    94.000000  0.000000e+00      5.600000   \n",
      "50%    1.500000e+07    12.928897   103.500000  1.918199e+07      6.200000   \n",
      "75%    4.000000e+07    28.350828   118.000000  9.291920e+07      6.800000   \n",
      "max    3.800000e+08   875.581305   338.000000  2.787965e+09     10.000000   \n",
      "\n",
      "         vote_count  \n",
      "count   4806.000000  \n",
      "mean     690.758427  \n",
      "std     1234.454061  \n",
      "min        0.000000  \n",
      "25%       54.000000  \n",
      "50%      236.000000  \n",
      "75%      737.750000  \n",
      "max    13752.000000  \n"
     ]
    }
   ],
   "source": [
    "# Cell 10 ‚Äî Prepare ML Dataset (for hit prediction model)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SECTION 2: ML MODELS - Hit Prediction (Rating >= 7.0)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build ML dataset with numeric features\n",
    "movie_ml = df[['id', 'movie_id', 'title', 'budget', 'popularity', 'runtime', 'revenue', 'vote_average', 'vote_count']].copy()\n",
    "\n",
    "# Clean numeric columns\n",
    "num_cols = ['budget', 'popularity', 'runtime', 'revenue', 'vote_average', 'vote_count']\n",
    "for c in num_cols:\n",
    "    movie_ml[c] = pd.to_numeric(movie_ml[c], errors='coerce').fillna(0)\n",
    "\n",
    "# Create binary classification target: hit = rating >= 7.0\n",
    "movie_ml['hit'] = (movie_ml['vote_average'] >= 7.0).astype(int)\n",
    "\n",
    "print(f\"‚úì ML dataset created: {movie_ml.shape[0]} movies\")\n",
    "print(f\"  Hit movies (rating >= 7.0): {movie_ml['hit'].sum()} ({movie_ml['hit'].mean()*100:.1f}%)\")\n",
    "print(f\"  Non-hit movies: {(1-movie_ml['hit']).sum()} ({(1-movie_ml['hit']).mean()*100:.1f}%)\")\n",
    "print(f\"\\nFeature summary:\")\n",
    "print(movie_ml[num_cols].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ee954d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-hot encoding genres...\n",
      "‚úì Features engineered: 25 features for 4806 movies\n",
      "  Numeric features: 5\n",
      "  Genre features: 20\n"
     ]
    }
   ],
   "source": [
    "# Cell 10b ‚Äî One-Hot Encode Genres for ML Features\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "print(\"\\nOne-hot encoding genres...\")\n",
    "\n",
    "# Get genres for all movies\n",
    "def genres_list_from_raw(obj):\n",
    "    try:\n",
    "        return [i.get('name', '').replace(\" \", \"\") for i in ast.literal_eval(obj)]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "genres_map = {}\n",
    "for _, row in movies_full.iterrows():\n",
    "    try:\n",
    "        gid = row['id']\n",
    "        genres_map[gid] = genres_list_from_raw(row['genres'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "movie_ml['genres'] = movie_ml['id'].apply(lambda x: genres_map.get(x, []))\n",
    "\n",
    "# Multi-label binarize genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_features = mlb.fit_transform(movie_ml['genres'])\n",
    "genre_df = pd.DataFrame(\n",
    "    genre_features, \n",
    "    columns=[c.replace(\" \", \"\") for c in mlb.classes_],\n",
    "    index=movie_ml.index\n",
    ")\n",
    "\n",
    "# Combine numeric + genre features\n",
    "features_numeric = ['budget', 'popularity', 'runtime', 'revenue', 'vote_count']\n",
    "X_full = pd.concat([movie_ml[features_numeric], genre_df], axis=1)\n",
    "y_full = movie_ml['hit']\n",
    "\n",
    "print(f\"‚úì Features engineered: {X_full.shape[1]} features for {X_full.shape[0]} movies\")\n",
    "print(f\"  Numeric features: {len(features_numeric)}\")\n",
    "print(f\"  Genre features: {genre_df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4c9f60b-a332-4e5f-896c-f7efd97ad63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data (80% train, 20% test with stratification)...\n",
      "‚úì Train set: 3844 samples\n",
      "‚úì Test set: 962 samples\n",
      "  Train hit rate: 20.5%\n",
      "  Test hit rate: 20.6%\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 ‚Äî Train/Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"\\nSplitting data (80% train, 20% test with stratification)...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_full, y_full, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_full\n",
    ")\n",
    "\n",
    "print(f\"‚úì Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"‚úì Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"  Train hit rate: {y_train.mean()*100:.1f}%\")\n",
    "print(f\"  Test hit rate: {y_test.mean()*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc0b5751-8f2b-4e29-a3e8-ccdd72e77d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL 1: RandomForest Classifier\n",
      "======================================================================\n",
      "\n",
      "Training RandomForest with GridSearchCV...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "\n",
      "‚úì RandomForest training complete\n",
      "  Best params: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  Best CV F1 score: 0.5318\n"
     ]
    }
   ],
   "source": [
    "# Cell 12 ‚Äî Train RandomForest Classifier with GridSearch\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 1: RandomForest Classifier\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nTraining RandomForest with GridSearchCV...\")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    rf, param_grid, \n",
    "    cv=3, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "print(f\"\\n‚úì RandomForest training complete\")\n",
    "print(f\"  Best params: {grid_rf.best_params_}\")\n",
    "print(f\"  Best CV F1 score: {grid_rf.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef6b1749-b364-4003-87ff-da9f212cc647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating RandomForest on test set...\n",
      "  Accuracy:  0.8669\n",
      "  Precision: 0.7917\n",
      "  Recall:    0.4798\n",
      "  F1-Score:  0.5975\n",
      "  ROC-AUC:   0.8939\n",
      "\n",
      "Confusion Matrix:\n",
      "[[739  25]\n",
      " [103  95]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       764\n",
      "           1       0.79      0.48      0.60       198\n",
      "\n",
      "    accuracy                           0.87       962\n",
      "   macro avg       0.83      0.72      0.76       962\n",
      "weighted avg       0.86      0.87      0.85       962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 13 ‚Äî Evaluate RandomForest\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"\\nEvaluating RandomForest on test set...\")\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'precision': precision_score(y_test, y_pred_rf),\n",
    "    'recall': recall_score(y_test, y_pred_rf),\n",
    "    'f1': f1_score(y_test, y_pred_rf),\n",
    "    'roc_auc': roc_auc_score(y_test, y_proba_rf)\n",
    "}\n",
    "\n",
    "print(f\"  Accuracy:  {rf_results['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {rf_results['precision']:.4f}\")\n",
    "print(f\"  Recall:    {rf_results['recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {rf_results['f1']:.4f}\")\n",
    "print(f\"  ROC-AUC:   {rf_results['roc_auc']:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\\n{confusion_matrix(y_test, y_pred_rf)}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred_rf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6d5f1e4-2a0c-401b-86f1-8ee3eb4d7a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL 2: XGBoost or HistGradientBoosting\n",
      "======================================================================\n",
      "\n",
      "Training XGBoost/HistGB model...\n",
      "  Using XGBClassifier\n",
      "‚úì Model training complete\n",
      "\n",
      "Evaluation Results:\n",
      "  Accuracy:  0.8565\n",
      "  Precision: 0.7174\n",
      "  Recall:    0.5000\n",
      "  F1-Score:  0.5893\n",
      "  ROC-AUC:   0.8873\n",
      "\n",
      "Confusion Matrix:\n",
      "[[725  39]\n",
      " [ 99  99]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 14 ‚Äî Train XGBoost/HistGradientBoosting Classifier\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 2: XGBoost or HistGradientBoosting\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nTraining XGBoost/HistGB model...\")\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    print(\"  Using XGBClassifier\")\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=200, \n",
    "        learning_rate=0.1, \n",
    "        max_depth=5, \n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "else:\n",
    "    print(\"  Using HistGradientBoostingClassifier (XGBoost not available)\")\n",
    "    from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "    xgb = HistGradientBoostingClassifier(\n",
    "        max_iter=200, \n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print(f\"‚úì Model training complete\")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_proba_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb_results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_xgb),\n",
    "    'precision': precision_score(y_test, y_pred_xgb),\n",
    "    'recall': recall_score(y_test, y_pred_xgb),\n",
    "    'f1': f1_score(y_test, y_pred_xgb),\n",
    "    'roc_auc': roc_auc_score(y_test, y_proba_xgb)\n",
    "}\n",
    "\n",
    "print(f\"\\nEvaluation Results:\")\n",
    "print(f\"  Accuracy:  {xgb_results['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {xgb_results['precision']:.4f}\")\n",
    "print(f\"  Recall:    {xgb_results['recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {xgb_results['f1']:.4f}\")\n",
    "print(f\"  ROC-AUC:   {xgb_results['roc_auc']:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\\n{confusion_matrix(y_test, y_pred_xgb)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b165e4f9-fbcf-46df-841c-3246fbfbd5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON: RandomForest vs XGBoost/HistGB\n",
      "======================================================================\n",
      "\n",
      "   Metric RandomForest XGBoost/HistGB\n",
      " Accuracy       0.8669         0.8565\n",
      "Precision       0.7917         0.7174\n",
      "   Recall       0.4798         0.5000\n",
      " F1-Score       0.5975         0.5893\n",
      "  ROC-AUC       0.8939         0.8873\n",
      "\n",
      "üèÜ Winner (by F1-Score): RandomForest\n"
     ]
    }
   ],
   "source": [
    "# Cell 15 ‚Äî Model Comparison Table\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: RandomForest vs XGBoost/HistGB\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
    "    'RandomForest': [\n",
    "        f\"{rf_results['accuracy']:.4f}\",\n",
    "        f\"{rf_results['precision']:.4f}\",\n",
    "        f\"{rf_results['recall']:.4f}\",\n",
    "        f\"{rf_results['f1']:.4f}\",\n",
    "        f\"{rf_results['roc_auc']:.4f}\"\n",
    "    ],\n",
    "    'XGBoost/HistGB': [\n",
    "        f\"{xgb_results['accuracy']:.4f}\",\n",
    "        f\"{xgb_results['precision']:.4f}\",\n",
    "        f\"{xgb_results['recall']:.4f}\",\n",
    "        f\"{xgb_results['f1']:.4f}\",\n",
    "        f\"{xgb_results['roc_auc']:.4f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# Determine winner\n",
    "rf_f1 = rf_results['f1']\n",
    "xgb_f1 = xgb_results['f1']\n",
    "winner = \"RandomForest\" if rf_f1 > xgb_f1 else \"XGBoost/HistGB\"\n",
    "print(f\"\\nüèÜ Winner (by F1-Score): {winner}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0e62935-e7af-4f4b-bb82-20cfa7ed9c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE\n",
      "======================================================================\n",
      "\n",
      "Top 15 features (RandomForest):\n",
      "vote_count        0.195287\n",
      "runtime           0.171527\n",
      "popularity        0.169335\n",
      "budget            0.134007\n",
      "revenue           0.110758\n",
      "Drama             0.032650\n",
      "Action            0.017418\n",
      "Comedy            0.016864\n",
      "Thriller          0.015865\n",
      "Romance           0.015677\n",
      "Documentary       0.012907\n",
      "Crime             0.012361\n",
      "Adventure         0.011954\n",
      "Mystery           0.009352\n",
      "ScienceFiction    0.009203\n",
      "dtype: float64\n",
      "\n",
      "Genre features importance (RandomForest):\n",
      "Drama             0.032650\n",
      "Action            0.017418\n",
      "Comedy            0.016864\n",
      "Thriller          0.015865\n",
      "Romance           0.015677\n",
      "Documentary       0.012907\n",
      "Crime             0.012361\n",
      "Adventure         0.011954\n",
      "Mystery           0.009352\n",
      "ScienceFiction    0.009203\n",
      "dtype: float64\n",
      "\n",
      "Numeric features importance (RandomForest):\n",
      "budget        0.134007\n",
      "popularity    0.169335\n",
      "runtime       0.171527\n",
      "revenue       0.110758\n",
      "vote_count    0.195287\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 16 ‚Äî Feature Importance Analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# RandomForest feature importance\n",
    "print(\"\\nTop 15 features (RandomForest):\")\n",
    "rf_importances = pd.Series(best_rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print(rf_importances.head(15))\n",
    "\n",
    "print(f\"\\nGenre features importance (RandomForest):\")\n",
    "genre_cols = [c for c in X_train.columns if c in mlb.classes_ or any(g in c for g in mlb.classes_)]\n",
    "genre_importance = rf_importances[[c for c in rf_importances.index if c in genre_cols]].head(10)\n",
    "print(genre_importance)\n",
    "\n",
    "print(f\"\\nNumeric features importance (RandomForest):\")\n",
    "numeric_importance = rf_importances[features_numeric]\n",
    "print(numeric_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2862fa6-7288-4d14-8169-17c13bb6a69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BONUS: Regression Model - Rating Prediction\n",
      "======================================================================\n",
      "\n",
      "Training RandomForestRegressor to predict vote_average...\n",
      "‚úì Regression model trained\n",
      "  RMSE: 0.7797\n",
      "  MAE:  0.5633\n",
      "  R¬≤:   0.5213\n"
     ]
    }
   ],
   "source": [
    "# Cell 17 ‚Äî Train Regression Model (Rating Prediction)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BONUS: Regression Model - Rating Prediction\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nTraining RandomForestRegressor to predict vote_average...\")\n",
    "\n",
    "X_reg = movie_ml[features_numeric].copy()\n",
    "y_reg = movie_ml['vote_average']\n",
    "\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "regressor.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "y_reg_pred = regressor.predict(X_reg_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_reg_test, y_reg_pred))\n",
    "r2 = r2_score(y_reg_test, y_reg_pred)\n",
    "mae = np.mean(np.abs(y_reg_test - y_reg_pred))\n",
    "\n",
    "print(f\"‚úì Regression model trained\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAE:  {mae:.4f}\")\n",
    "print(f\"  R¬≤:   {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "270c323f-6d2c-44e1-8d64-ef02378ae851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING ARTIFACTS\n",
      "======================================================================\n",
      "\n",
      "Saving content-based recommendation artifacts...\n",
      "Saving ML classification models...\n",
      "Saving feature metadata...\n",
      "\n",
      "‚úì All artifacts saved successfully!\n",
      "  Movies metadata: movies_metadata.pkl\n",
      "  TF-IDF vectors: tfidf_vectors.pkl, tfidf_similarity.pkl\n",
      "  KNN model: knn_model.pkl, count_vectors.pkl\n",
      "  Classifiers: classifier_rf.pkl, classifier_xgb.pkl\n",
      "  Regressor: regressor_rating.pkl\n",
      "  Vectorizers: tfidf_vectorizer.pkl, count_vectorizer.pkl\n",
      "  Metadata: feature_columns.pkl, movie_data_ml.pkl, genre_classes.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 18 ‚Äî Save All Artifacts for Production\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING ARTIFACTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "out_dir = Path(\".\")\n",
    "\n",
    "# Content-based artifacts\n",
    "print(\"\\nSaving content-based recommendation artifacts...\")\n",
    "pickle.dump(df[['movie_id', 'title', 'tags']], open(out_dir / 'movies_metadata.pkl', 'wb'))\n",
    "pickle.dump(tfidf_vectors, open(out_dir / 'tfidf_vectors.pkl', 'wb'))\n",
    "pickle.dump(tfidf_similarity, open(out_dir / 'tfidf_similarity.pkl', 'wb'))\n",
    "pickle.dump(count_vectors, open(out_dir / 'count_vectors.pkl', 'wb'))\n",
    "pickle.dump(knn_model, open(out_dir / 'knn_model.pkl', 'wb'))\n",
    "pickle.dump(tfidf, open(out_dir / 'tfidf_vectorizer.pkl', 'wb'))\n",
    "pickle.dump(count_vec, open(out_dir / 'count_vectorizer.pkl', 'wb'))\n",
    "\n",
    "# ML models\n",
    "print(\"Saving ML classification models...\")\n",
    "pickle.dump(best_rf, open(out_dir / 'classifier_rf.pkl', 'wb'))\n",
    "pickle.dump(xgb, open(out_dir / 'classifier_xgb.pkl', 'wb'))\n",
    "pickle.dump(regressor, open(out_dir / 'regressor_rating.pkl', 'wb'))\n",
    "\n",
    "# Feature metadata\n",
    "print(\"Saving feature metadata...\")\n",
    "pickle.dump(X_train.columns, open(out_dir / 'feature_columns.pkl', 'wb'))\n",
    "pickle.dump(movie_ml[['id', 'movie_id', 'title', 'budget', 'popularity', 'vote_average']], \n",
    "            open(out_dir / 'movie_data_ml.pkl', 'wb'))\n",
    "pickle.dump(mlb.classes_, open(out_dir / 'genre_classes.pkl', 'wb'))\n",
    "\n",
    "print(f\"\\n‚úì All artifacts saved successfully!\")\n",
    "print(f\"  Movies metadata: movies_metadata.pkl\")\n",
    "print(f\"  TF-IDF vectors: tfidf_vectors.pkl, tfidf_similarity.pkl\")\n",
    "print(f\"  KNN model: knn_model.pkl, count_vectors.pkl\")\n",
    "print(f\"  Classifiers: classifier_rf.pkl, classifier_xgb.pkl\")\n",
    "print(f\"  Regressor: regressor_rating.pkl\")\n",
    "print(f\"  Vectorizers: tfidf_vectorizer.pkl, count_vectorizer.pkl\")\n",
    "print(f\"  Metadata: feature_columns.pkl, movie_data_ml.pkl, genre_classes.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23f517cd-cf05-4447-a0a1-ba2e4957c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PROJECT SUMMARY\n",
      "======================================================================\n",
      "\n",
      "SECTION 1: CONTENT-BASED RECOMMENDATION SYSTEMS\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Method 1 - TF-IDF + Cosine Similarity:\n",
      "  ‚Ä¢ Vectorization method: TF-IDF (term frequency-inverse document frequency)\n",
      "  ‚Ä¢ Similarity metric: Cosine similarity\n",
      "  ‚Ä¢ Setup time: 0.65s\n",
      "  ‚Ä¢ Features: 5000 dimensions\n",
      "  \n",
      "  Pros: Fast queries, statistically weighted, interpretable\n",
      "  Cons: Memory intensive (stores full similarity matrix)\n",
      "\n",
      "Method 2 - KNN (K-Nearest Neighbors):\n",
      "  ‚Ä¢ Vectorization method: Count Vectorizer\n",
      "  ‚Ä¢ Distance metric: Cosine distance\n",
      "  ‚Ä¢ Setup time: 0.31s\n",
      "  ‚Ä¢ Features: 5000 dimensions\n",
      "  ‚Ä¢ K: 6 neighbors\n",
      "  \n",
      "  Pros: Flexible, memory efficient, tunable k\n",
      "  Cons: Slower queries, requires full scan without indexing\n",
      "\n",
      "Recommendation Comparison:\n",
      "  Test query: \"The Dark Knight\"\n",
      "  Overlap: 4/5 movies\n",
      "\n",
      "SECTION 2: ML CLASSIFICATION MODELS\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Dataset: 3844 training samples, 962 test samples\n",
      "Task: Binary classification - Predict if movie is a \"hit\" (rating >= 7.0)\n",
      "Features: 25 (numeric + one-hot genres)\n",
      "Class distribution: Hit=20.5% / Non-hit=79.5%\n",
      "\n",
      "Model 1 - RandomForest:\n",
      "  ‚Ä¢ Best hyperparameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  ‚Ä¢ F1-Score: 0.5975\n",
      "  ‚Ä¢ ROC-AUC: 0.8939\n",
      "  ‚Ä¢ Accuracy: 0.8669\n",
      "\n",
      "Model 2 - XGBoost/HistGradientBoosting:\n",
      "  ‚Ä¢ F1-Score: 0.5893\n",
      "  ‚Ä¢ ROC-AUC: 0.8873\n",
      "  ‚Ä¢ Accuracy: 0.8565\n",
      "\n",
      "Winner (by F1-Score): RandomForest\n",
      "\n",
      "Regression Model (Bonus):\n",
      "  ‚Ä¢ Task: Predict vote_average (movie rating)\n",
      "  ‚Ä¢ Model: RandomForestRegressor\n",
      "  ‚Ä¢ RMSE: 0.7797\n",
      "  ‚Ä¢ R¬≤: 0.5213\n",
      "\n",
      "SAVED ARTIFACTS:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úì Content-based: movies_metadata.pkl, tfidf_*.pkl, knn_model.pkl\n",
      "‚úì Classifiers: classifier_rf.pkl, classifier_xgb.pkl\n",
      "‚úì Metadata: feature_columns.pkl, genre_classes.pkl, movie_data_ml.pkl\n",
      "\n",
      "Ready for Streamlit or production deployment!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 19 ‚Äî Summary Report\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary = f\"\"\"\n",
    "SECTION 1: CONTENT-BASED RECOMMENDATION SYSTEMS\n",
    "{'‚îÄ'*70}\n",
    "\n",
    "Method 1 - TF-IDF + Cosine Similarity:\n",
    "  ‚Ä¢ Vectorization method: TF-IDF (term frequency-inverse document frequency)\n",
    "  ‚Ä¢ Similarity metric: Cosine similarity\n",
    "  ‚Ä¢ Setup time: {tfidf_metrics['total_time']:.2f}s\n",
    "  ‚Ä¢ Features: {tfidf_metrics['matrix_shape'][1]} dimensions\n",
    "  \n",
    "  Pros: Fast queries, statistically weighted, interpretable\n",
    "  Cons: Memory intensive (stores full similarity matrix)\n",
    "\n",
    "Method 2 - KNN (K-Nearest Neighbors):\n",
    "  ‚Ä¢ Vectorization method: Count Vectorizer\n",
    "  ‚Ä¢ Distance metric: Cosine distance\n",
    "  ‚Ä¢ Setup time: {knn_metrics['total_time']:.2f}s\n",
    "  ‚Ä¢ Features: {knn_metrics['matrix_shape'][1]} dimensions\n",
    "  ‚Ä¢ K: {knn_metrics['n_neighbors']} neighbors\n",
    "  \n",
    "  Pros: Flexible, memory efficient, tunable k\n",
    "  Cons: Slower queries, requires full scan without indexing\n",
    "\n",
    "Recommendation Comparison:\n",
    "  Test query: \"{test_movies[0] if test_movies else 'N/A'}\"\n",
    "  Overlap: {comparison_results[0]['overlap'] if comparison_results else 0}/5 movies\n",
    "\n",
    "SECTION 2: ML CLASSIFICATION MODELS\n",
    "{'‚îÄ'*70}\n",
    "\n",
    "Dataset: {X_train.shape[0]} training samples, {X_test.shape[0]} test samples\n",
    "Task: Binary classification - Predict if movie is a \"hit\" (rating >= 7.0)\n",
    "Features: {X_train.shape[1]} (numeric + one-hot genres)\n",
    "Class distribution: Hit={y_train.mean()*100:.1f}% / Non-hit={(1-y_train.mean())*100:.1f}%\n",
    "\n",
    "Model 1 - RandomForest:\n",
    "  ‚Ä¢ Best hyperparameters: {grid_rf.best_params_}\n",
    "  ‚Ä¢ F1-Score: {rf_results['f1']:.4f}\n",
    "  ‚Ä¢ ROC-AUC: {rf_results['roc_auc']:.4f}\n",
    "  ‚Ä¢ Accuracy: {rf_results['accuracy']:.4f}\n",
    "\n",
    "Model 2 - XGBoost/HistGradientBoosting:\n",
    "  ‚Ä¢ F1-Score: {xgb_results['f1']:.4f}\n",
    "  ‚Ä¢ ROC-AUC: {xgb_results['roc_auc']:.4f}\n",
    "  ‚Ä¢ Accuracy: {xgb_results['accuracy']:.4f}\n",
    "\n",
    "Winner (by F1-Score): {winner}\n",
    "\n",
    "Regression Model (Bonus):\n",
    "  ‚Ä¢ Task: Predict vote_average (movie rating)\n",
    "  ‚Ä¢ Model: RandomForestRegressor\n",
    "  ‚Ä¢ RMSE: {rmse:.4f}\n",
    "  ‚Ä¢ R¬≤: {r2:.4f}\n",
    "\n",
    "SAVED ARTIFACTS:\n",
    "{'‚îÄ'*70}\n",
    "‚úì Content-based: movies_metadata.pkl, tfidf_*.pkl, knn_model.pkl\n",
    "‚úì Classifiers: classifier_rf.pkl, classifier_xgb.pkl\n",
    "‚úì Metadata: feature_columns.pkl, genre_classes.pkl, movie_data_ml.pkl\n",
    "\n",
    "Ready for Streamlit or production deployment!\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "880d86bb-d5af-4434-b87c-8808be294f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "QUICK TEST: Compare TF-IDF vs KNN on Single Movie\n",
      "======================================================================\n",
      "\n",
      "Finding similar movies to 'Inception'...\n",
      "\n",
      "TF-IDF Method:\n",
      "  1. Don Jon                                            (similarity: 0.1728)\n",
      "  2. Premium Rush                                       (similarity: 0.1504)\n",
      "  3. Cypher                                             (similarity: 0.1452)\n",
      "  4. Hesher                                             (similarity: 0.1353)\n",
      "  5. Duplex                                             (similarity: 0.1308)\n",
      "\n",
      "KNN Method:\n",
      "  1. Duplex                                             (similarity: 0.5621)\n",
      "  2. The Helix... Loaded                                (similarity: 0.5568)\n",
      "  3. Star Trek II: The Wrath of Khan                    (similarity: 0.5558)\n",
      "  4. Timecop                                            (similarity: 0.5548)\n",
      "  5. Chicago Overcoat                                   (similarity: 0.5544)\n",
      "\n",
      "‚úì Both methods completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 20 ‚Äî Quick Test (Run Both Methods on Same Movie)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QUICK TEST: Compare TF-IDF vs KNN on Single Movie\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_movie_final = \"Inception\"\n",
    "\n",
    "print(f\"\\nFinding similar movies to '{test_movie_final}'...\\n\")\n",
    "\n",
    "tfidf_t, tfidf_i, tfidf_s = recommend_tfidf(test_movie_final, top_n=5)\n",
    "knn_t, knn_i, knn_s = recommend_knn(test_movie_final, top_n=5)\n",
    "\n",
    "if len(tfidf_t) == 0:\n",
    "    print(f\"Movie '{test_movie_final}' not found in dataset\")\n",
    "else:\n",
    "    print(\"TF-IDF Method:\")\n",
    "    for rank, (title, score) in enumerate(zip(tfidf_t, tfidf_s), 1):\n",
    "        print(f\"  {rank}. {title:50} (similarity: {score:.4f})\")\n",
    "    \n",
    "    print(\"\\nKNN Method:\")\n",
    "    for rank, (title, score) in enumerate(zip(knn_t, knn_s), 1):\n",
    "        print(f\"  {rank}. {title:50} (similarity: {score:.4f})\")\n",
    "    \n",
    "    print(\"\\n‚úì Both methods completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d19a451-1cbf-43dd-83a0-a14a06a75fb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(X\u001b[38;5;241m.\u001b[39mcolumns, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump(X.columns, open(\"columns.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863274c-c680-420b-9c48-9673e1b60e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
